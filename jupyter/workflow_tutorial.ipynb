{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Tutorial\n",
    "\n",
    "This text is designed to help someone set up a `fireworks` server and start creating workflows. In principle, it's also possible to just follow the tutorials on the [Fireworks website](https://materialsproject.github.io/fireworks/), but this will be a more succinct version, which stays focused on setting up the workflows using Python, instead of `.yaml` files. There is also a little more info about how to set up the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the server\n",
    "\n",
    "The standard approach for using the workflows (or, at least, _my_ standard approach), is to set up a mongoDB server using mongoDB Atlas and submitting workflows to this server using the Fireworks `lpad` command. So, the first step is to set up such a server, which we can later use as a home for our workflows.\n",
    "\n",
    "First: go the the [mongoDB Atlas website](https://www.mongodb.com/cloud/atlas) and set up an account. Next, create a new project using the context menu on the top left. Give it a suitable name (e.g. Workflow Tutorial) and press \"Create Project\". Next, it's time to create a cluster, by pressing the \"Build a Cluster\" button in the center of the screen. Now, let's go over the various click-down menu's available on the cluster creation screen:\n",
    "\n",
    "* __Global Cluster Configuration__: Just ignore this one. This only matters in case you want a very high tier (i.e. expensive) cluster.\n",
    "* __Cloud Provider & Region__: Here you can choose the location of the server, as well as the service that provides it. Choose whatever region and provider you prefer. I will choose Google Cloud Platform, because they have free tiers available in Belgium. Make sure the region you choose also has free tiers available. \n",
    "* __Cluster Tier__: For the cluster tier, choose the M0. This is the only free one.\n",
    "* __Additional Settings__: You can safely ignore this tab, as you can't make any choices here, unless you're willing to pay.\n",
    "* __Cluster Name__: Pretty self-explanatory.\n",
    "\n",
    "Setting up the cluster takes a little time. This is the perfect time for some [covfefe](https://www.amazon.com/Covfefe-Mug-11oz-Presidential-Alternative/dp/B072Q1B52J).\n",
    "\n",
    "Once the cluster is set up, you need to set up the Admin user, and whitelist all ip's to be able to connect to the cluster. Go to the \"Security\" tab next to the \"Overview\" tab, and then use the \"Add New User\" button to set up a new user. Type a username and password, and make sure to select \"Atlas Admin\" privileges. Next, go the \"IP Whitelist\" subtab and click on \"Add IP Adress\". Click on \"Allow Access From Everywhere\" and confirm to simply whitelist all IP addresses. On an actual cluster you use for production runs, I would just whitelist the IP adresses from whatever machine you run the workflows on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Python environment\n",
    "\n",
    "The next part of the tutorial involves setting up the python environment that can access the cluster and hence submit the workflows. This part of the tutorial will be focused on doing this on the computing resources of Lawrence Livermore National Laboratory (LLNL). I hope to add a more general tutorial later.\n",
    "\n",
    "Connect to any LC machine. I'll use quartz for this tutorial, but in principle it should not matter. Once you're connected, it's best to install miniconda to set up the environment. Miniconda will also automatically install Python v3.7, which will be much faster to use than the python that comes with the modules on the cluster. First, create a suitable directory for installing miniconda in. I've chosen `$HOME/python/miniconda3`. Next, download the miniconda installer and run it:\n",
    "\n",
    "```\n",
    "wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "bash Miniconda3-latest-Linux-x86_64.sh\n",
    "```\n",
    "\n",
    "Once you accept the licence, the installation of miniconda will begin by installing Python v3.7 and the conda dependencies. This will take a while, so get more covfefe. Executing python commands on LC seems to be pretty slow in general, so you'll have to be a little patient in setting up the Python environment (PS: If you have a solution for this, please tell me. Working with python on LC is frustratingly slow). The conda installer will have added a line that redefines the `PATH` in your `~/.bashrc`. This is currently not the prefered method of activating conda, however. As LC uses `~/.bash_profile` for setting up the environment, you can in principle safely delete the newly created `.bashrc` file. (Unless you somehow are using this file to set up your linux environment). Setting up the conda environment will most likely not work after the install, as the `conda` command will not be known. This can be fixed with the following commands:\n",
    "\n",
    "```\n",
    "echo \". $HOME/miniconda3/etc/profile.d/conda.sh\" >> ~/.bash_profile\n",
    "source ~/.bash_profile\n",
    "```\n",
    "\n",
    "Now you should be able to activate the 'base' environment by using the `conda activate` command. However, it's best to set up specific environments for each purpose. Let's set up a python environment for this tutorial. This can be done easily with conda:\n",
    "\n",
    "```\n",
    "conda create -n tutorial\n",
    "```\n",
    "\n",
    "You can activate the environment by now using the command `conda activate tutorial`. Once you've activated the environment, I usually install pip for the installation of other python packages:\n",
    "\n",
    "```\n",
    "conda install pip\n",
    "```\n",
    "\n",
    "This took ages for me. No covfefe-break should ever take this long. Finally, we can install the `fireworks` package to finish setting up the environment for the tutorial:\n",
    "\n",
    "```\n",
    "pip install fireworks\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the launchpad\n",
    "\n",
    "In order to interact with the mongoDB server, we need to set up the launchpad file. This turned out to be a little trickier when using mongoDB Atlas when compared to mlab. However, as mlab is merging with Atlas, I wanted to make it work. I finally found a solution on the [fireworks google group](https://groups.google.com/forum/#!topic/fireworkflows/0nBxQLap0Qk). Apparently setting up the MongoClient for Atlas requires an extra input argument `authsource` to be set to `admin`. I usually have a `launchpad` directory in my home directory with the appropriate subdirectories from which I manage the calculations on the server. This is done by setting up a `my_launchpad.yaml` file in this directory, and then using `lpad` to interact with the server. Below you can see the `my_launchpad.yaml` file I created to interact with the mongoDB Atlas database:\n",
    "\n",
    "```\n",
    "name: tutor\n",
    "host: \"mongodb+srv://tutorial-urpwq.gcp.mongodb.net\" \n",
    "port: 27017\n",
    "username: mbercx\n",
    "password: tutorial\n",
    "ssl: true\n",
    "authsource: admin\n",
    "```\n",
    "\n",
    "You can adjust as required. Here's some more information and tips on the various input:\n",
    "\n",
    "* The database name can be chosen freely; the database will be created when it is reset using `lpad reset`. Once the database has been reset, you will also find it under the \"Collections\" tab in your tutorial cluster on mongoDB Atlas.\n",
    "* For me, the `mongodb+srv://` prefix in the host is required for the connection to work. This also most likely will require the installation of the `dnspython` python package. To find the proper host, click on connect in the cluster overview, then on Connect with the Mongo shell. Under \"(2) Connect via the Mongo Shell\", you can then click on \"Short RSV sonnection string\", and copy the hostname from the mongo shell command.\n",
    "* The default port for mongoDB Atlas seems to be 27017. I have so far found no reason to change this.\n",
    "* The username and password should correspond with those you have set up in the first part of the tutorial.\n",
    "* Don't forget the ssl and authsource tags!\n",
    "\n",
    "Once you've set it up, you can use `lpad reset` to see if you can successfully reset the server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating your first workflow\n",
    "\n",
    "Now it's finally time to put some python in this notebook! Of course, if you want to use the commands in this notebook, you need to set up the conda environment properly on your local machine. This can be done in a similar fashion as for the cluster, with the addition of installing the `jupyterlab` package.\n",
    "\n",
    "In order to set up workflows that I can submit to the server, I set up a LAUNCHPAD global variable in the workflows module of my package. (In the newer version of a package I use here, I set up a configuration file for the launchpad, so the launchpad details are not just accessible via github). First, let's load the Launchpad class and set up an instance using the details of the server, which are directly copied from the `my_launchpad.yaml` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fireworks import LaunchPad\n",
    "\n",
    "LAUNCHPAD = LaunchPad(host=\"mongodb+srv://tutorial-urpwq.gcp.mongodb.net\", port=21017, name=\"tutor\",\n",
    "                      username=\"mbercx\", password=\"tutorial\", ssl=True, authsource=\"admin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're running this notebook, you can adjust the details according to the mongoDB Atlas database you have set up previously. Now, you can access the server information with the methods of the `LAUNCHPAD` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAUNCHPAD.get_fw_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be empty. However, we can set up some simple workflows to add to the server. Every workflow that is submitted to the server consists of FireWorks, which in turn consist of FireTasks. The best way to set up whatever workflow you want to perform depends on several elements. You can find more tips on this topic on [the fireworks website](https://materialsproject.github.io/fireworks/design_tips.html). Now I will simply show a very basic example of setting up a workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fireworks import ScriptTask, Firework, Workflow\n",
    "\n",
    "hello_task = ScriptTask.from_str(\"echo 'Hello, user!'\")\n",
    "intro_task = ScriptTask.from_str(\"echo 'My name is Billy!'\")\n",
    "\n",
    "fw1 = Firework(tasks=[hello_task, intro_task], name=\"Introduction\")\n",
    "\n",
    "glad_task = ScriptTask.from_str(\"echo 'I am glad to tell you that it worked!'\")\n",
    "\n",
    "fw2 = Firework(tasks=[glad_task], name=\"Success Message\")\n",
    "\n",
    "workflow = Workflow(fireworks=[fw1, fw2], name=\"My First Workflow\",\n",
    "                   links_dict={\"fw1\":[fw2]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few remarks:\n",
    "\n",
    "* The `FireTasks` are passed as a list to the `FireWork`, the `FireWorks` are passed as a list to the `WorkFlow`.\n",
    "* Note the `links_dict` argument for the `WorkFlow`. This determines the 'structure' of the workflow, i.e. which commands are executed in which succession. If the `links_dict` argument was not given, both `FireWorks` would be executed simultaneously. \n",
    "\n",
    "Next, we can sent it to the server with the `add_wf` method of the Launchpad instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-23 16:02:18,648 INFO Added a workflow. id_map: {-6: 1, -5: 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{-6: 1, -5: 2}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAUNCHPAD.add_wf(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now ask the launchpad for the list of fireworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LAUNCHPAD.get_fw_ids()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a list of 2 firework ID's. If you're running these commands in the notebook, and have adjusted the `LaunchPad` initialization arguments correctly, you can also go back to the directory on the cluster which contains the `my_launchpad.yaml` file and try executing the `lpad get_fws` command again. You should obtain the something similar to the following:\n",
    "\n",
    "```\n",
    "(tutorial) [bercx1@quartz380:tutorial]$ lpad get_fws\n",
    "[\n",
    "    {\n",
    "        \"fw_id\": 1,\n",
    "        \"created_on\": \"2018-12-23T14:47:24.600753\",\n",
    "        \"updated_on\": \"2018-12-23T14:47:25.762610\",\n",
    "        \"state\": \"READY\",\n",
    "        \"name\": \"Success Message\"\n",
    "    },\n",
    "    {\n",
    "        \"fw_id\": 2,\n",
    "        \"created_on\": \"2018-12-23T14:47:24.600697\",\n",
    "        \"updated_on\": \"2018-12-23T14:47:25.762614\",\n",
    "        \"state\": \"READY\",\n",
    "        \"name\": \"Introduction\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "While still in the directory which contains the `my_launchpad.yaml` file, you can launch one of the `WorkFlows` on the launchpad using the `rlaunch` command. Let's fire a single rocket (i.e. launch a single firework) for now:\n",
    "\n",
    "```\n",
    "(tutorial) [bercx1@quartz380:tutorial]$ rlaunch singleshot\n",
    "2018-12-23 07:02:48,035 INFO Hostname/IP lookup (this will take a few seconds)\n",
    "2018-12-23 07:02:48,037 INFO Launching Rocket\n",
    "2018-12-23 07:02:55,482 INFO RUNNING fw_id: 2 in directory: /g/g91/bercx1/launchpad/tutorial\n",
    "2018-12-23 07:02:56,961 INFO Task started: ScriptTask.\n",
    "Hello, user!\n",
    "2018-12-23 07:02:57,025 INFO Task completed: ScriptTask \n",
    "2018-12-23 07:02:57,309 INFO Task started: ScriptTask.\n",
    "My name is Billy!\n",
    "2018-12-23 07:02:57,313 INFO Task completed: ScriptTask \n",
    "2018-12-23 07:02:59,299 INFO Rocket finished\n",
    "```\n",
    "\n",
    "You can see all the information the mongoDB server communicates as it looks for a suitable `FireWork` to run and executes the `FireTasks` within. If you now check the fireworks on the server again:\n",
    "\n",
    "```\n",
    "(tutorial) [bercx1@quartz380:tutorial]$ lpad get_fws\n",
    "[\n",
    "    {\n",
    "        \"fw_id\": 1,\n",
    "        \"created_on\": \"2018-12-23T15:02:16.718093\",\n",
    "        \"updated_on\": \"2018-12-23T15:02:18.514967\",\n",
    "        \"state\": \"READY\",\n",
    "        \"name\": \"Success Message\"\n",
    "    },\n",
    "    {\n",
    "        \"fw_id\": 2,\n",
    "        \"created_on\": \"2018-12-23T15:02:16.718039\",\n",
    "        \"updated_on\": \"2018-12-23T15:02:58.733314\",\n",
    "        \"state\": \"COMPLETED\",\n",
    "        \"name\": \"Introduction\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "You can see that one of them has been marked as `COMPLETED`. You can run the `rlaunch singleshot` command again, which will run the `ScriptTask` in the second `FireWork`. Attempting to launch another rocket will get you the message: `No FireWorks are ready to run and match query!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running FireWorks via the queueing system\n",
    "\n",
    "In the example above, the `rlaunch` command was simply run from the prompt after logging onto LC, and hence was executed by the login nodes. In practise, we want to use the queuing system to submit jobs to the computational nodes of whatever cluster we're working on. On LC, here is the script I've used so far:\n",
    "\n",
    "```\n",
    "(tutorial) [bercx1@quartz1532:tutorial]$ more 1node.sh \n",
    "#!/bin/bash\n",
    "#MSUB -S /bin/bash\n",
    "#MSUB -N cage_workflows\n",
    "#MSUB -j eo\n",
    "#MSUB -o FW_logs.out\n",
    "#MSUB -l partition=quartz\n",
    "#MSUB -l nodes=1\n",
    "#MSUB -q pbatch\n",
    "#MSUB -l walltime=24:00:00\n",
    "#MSUB -A pls2\n",
    "#MSUB -V   #pass-through environment variables\n",
    "##MSUB -m e  #send email when job completes\n",
    "\n",
    "conda activate tutorial\n",
    "\n",
    "rlaunch -w /g/g91/bercx1/launchpad/tutorial/my_fworker.yaml -l /g/g91/bercx1/launchpad/tutorial/my_launchpad.yaml rapidfire --nlaunches infinite --sleep 10 --timeout 72000\n",
    "\n",
    "exit\n",
    "\n",
    "```\n",
    "\n",
    "This script will run for 24 hrs on a single node, continuously asking for work every 10 seconds until it reaches the timeout of 20 hrs. Let's discuss the various aspects of the commands in the script:\n",
    "\n",
    "* `conda activate tutorial` activates the conda environment. This is needed for the cluster to recognize the `rlaunch` command.\n",
    "* `rlaunch` requests for FireWorks from the mongoDB Atlas server, just like we did before, but now within the queue submission script.\n",
    "* The `-w` option allows us to specify the `FireWorker` file. This one is pretty much empty atm:<br/><br/>\n",
    "```\n",
    "(tutorial) [bercx1@quartz1532:tutorial]$ more my_fworker.yaml \n",
    "name: quartz\n",
    "category: ''\n",
    "query: '{}'\n",
    "```\n",
    "<br/>\n",
    "So far I've only used the `category` tag to specify the amount of nodes for `FireWorks`. I'll get into that later. For now, you can just use however many nodes you need for the most computationally expensive step in your workflow.\n",
    "* The `-l` option allows you to specify the `my_launchpad.yaml` file that should be used. Just pass it the full absolute path to the launchpad file you set up earlier.\n",
    "* `rapidfire` is the subcommand that lets the `rlaunch` command to continuously keep on 'firing rockets', i.e. asking for work from the mongoDB Atlas server.\n",
    "* `--nlaunches` is the option that indicates the amount of launches that should be performed consecutively. By setting it to `infinite`, the `rlaunch` command will keep on requesting work from the mongoDB Atlas server.\n",
    "* `--sleep 10` just lets the launcher wait ten seconds in between each communication with the mongoDB Atlas server when requesting work.\n",
    "* `--timeout 72000` means that the `rlaunch` command will stop requesting work after 20 hrs (72000 seconds). This is to try and avoid calculations running into the walltime.\n",
    "\n",
    "Submitting this script to the cluster via `msub 1node.sh` should work fine, and once it starts running it should set up the conda environment and start running whatever FireWorks are on the tutorial server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running something more serious\n",
    "\n",
    "So far we've only used the `ScriptTask` FireTask to set up the various tasks in the workflow. Usually, the type of task I use most is the `PyTask`, as this allows me to run any Python script inside the workflow. The example code below is the one I use to optimize the geometry of the molecule before adding the cation and calculating the landscape.\n",
    "\n",
    "```Python\n",
    "import os\n",
    "\n",
    "from cage.core import Cage\n",
    "from fireworks import LaunchPad\n",
    "\n",
    "LAUNCHPAD = LaunchPad(host=\"mongodb+srv://tutorial-urpwq.gcp.mongodb.net\", port=21017, name=\"tutor\",\n",
    "                      username=\"mbercx\", password=\"tutorial\", ssl=True, authsource=\"admin\")\n",
    "\n",
    "RUN_NWCHEM_COMMAND = \"srun -N1 -n36 /g/g91/bercx1/nwchem/nwchem-6.6/bin/LINUX64/nwchem\"\n",
    "\n",
    "def optimize_workflow(filename, charge=0):\n",
    "    \"\"\"\n",
    "    Workflow for the optimization of a molecule\n",
    "\n",
    "    Args:\n",
    "        filename (str): Path to the structure file of the cage molecule.\n",
    "        Json formats with charge assigned are preferred.\n",
    "\n",
    "        charge (int): Charge of the molecule.\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    # Load the cage molecule from the filename provided\n",
    "    molecule = Cage.from_file(filename)\n",
    "\n",
    "    # Create the PyTask that sets up the calculation\n",
    "    setup_task = PyTask(\n",
    "        func=\"cage.cli.commands.setup.optimize\",\n",
    "        kwargs={\"filename\": filename,\n",
    "                \"charge\": charge}\n",
    "    )\n",
    "\n",
    "    optimize_dir = os.path.join(os.getcwd(), \"optimize\")\n",
    "\n",
    "    optimize_command = RUN_NWCHEM_COMMAND + \" \" \\\n",
    "                       + os.path.join(optimize_dir, \"input\") + \" > \" \\\n",
    "                       + os.path.join(optimize_dir, \"result.out\")\n",
    "\n",
    "    run_nwchem = ScriptTask.from_str(optimize_command)\n",
    "\n",
    "    fw = Firework(tasks=[setup_task, run_nwchem],\n",
    "                  name=\"Run Nwchem\")\n",
    "\n",
    "    LAUNCHPAD.add_wf(\n",
    "        Workflow(fireworks=[fw],\n",
    "                 name=\"Optimize \" + molecule.composition.reduced_formula)\n",
    "    )\n",
    "\n",
    "```\n",
    "\n",
    "Note that the `FireWork` consists of two `FireTasks`:\n",
    "\n",
    "1. A `PyTask` that sets up the NwChem calculation in the `./optimize` directory. This python method is defined in the `cage.cli.commands.setup` module.\n",
    "2. A `ScriptTask` that runs the NwChem calculation. I compiled the NwChem binary (probably in a horribly inefficient manner, but hey) my first week at LLNL in the `/g/g91/bercx1/nwchem/nwchem-6.6/bin/LINUX64/` directory. You can find the command that is executed in the `ScriptTask` partially in the header of the code.\n",
    "\n",
    "When the `FireTasks` are set up, they are combined into a `FireWork`, simply called `fw`. This is then put into a single step `WorkFlow` and added to the LAUNCHPAD. When the `rlaunch` command in the submission script is called, `fireworks` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
